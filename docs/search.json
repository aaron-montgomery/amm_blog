[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi! I’m Aaron Montgomery, an Associate Professor at Baldwin Wallace University. I received a PhD in Mathematics (specializing in Probability Theory) in 2013 at the University of Oregon under the direction of David Levin. Since then, I have been a member of the BW Mathematics and Statistics faculty, and more recently I have become the coordinator of the new Data Science and Data Analytics programs.\nI am always open to collaborating on interesting statistical or data-oriented projects! You can reach me at amontgom (atsymbol) bw.edu."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "This blog is an assorted collection of notes on probability, statistics, data, and coding.\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nJan 26, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nJan 23, 2023\n\n\nAaron Montgomery\n\n\n\n\n\n\n  \n\n\n\n\nHey, Who Invited You?\n\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\nmonte-carlo\n\n\neulers-number\n\n\ncounterintuitive\n\n\n\n\nA coding problem brings an uninvited famous mathematical guest\n\n\n\n\n\n\nJul 27, 2022\n\n\nAaron Montgomery\n\n\n\n\n\n\n  \n\n\n\n\nLet’s Make a Deal!\n\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\nmonte-carlo\n\n\nmonty-hall\n\n\ncounterintuitive\n\n\n\n\nMonty Hall meets Monte Carlo\n\n\n\n\n\n\nJul 14, 2022\n\n\nAaron Montgomery\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2022-07-10-monty-hall/index.html",
    "href": "posts/2022-07-10-monty-hall/index.html",
    "title": "Let’s Make a Deal!",
    "section": "",
    "text": "Photo by Sebastian Herrmann on Unsplash"
  },
  {
    "objectID": "posts/2022-07-10-monty-hall/index.html#the-incorrect-answer",
    "href": "posts/2022-07-10-monty-hall/index.html#the-incorrect-answer",
    "title": "Let’s Make a Deal!",
    "section": "The Incorrect Answer",
    "text": "The Incorrect Answer\nI was first exposed to this problem in college when a friend posed the question to me as a brain teaser to at a cafeteria table. I gave the only sensible answer, which was to say that since you had two doors, getting the prize was a 50/50 proposition no matter what you chose. I was, of course, dead wrong.\nFor years, I was slightly embarrassed about this. Not too embarrassed, mind you – after all, I’m wrong all the time. But this one stung because my friend was on my home turf; at this point in my life, I was pretty sure I was going to try to pursue a PhD in Mathematics and I suspected I might gravitate to the field of Probability Theory. Just like that, I whiffed on a probability question in a semi-public forum.\nMy shame was lessened over the years when I learned that if nothing else, I wasn’t alone. When Marilyn Vos Savant gave a correct solution to the problem in a 1990 issue of Parade, she received a truckload of letters, many from professional mathematicians, telling her how wrong she was. (She wasn’t wrong, which certainly didn’t help the outrageous rudeness of some of those letters.) In his book Which Door Has the Cadillac: Adventures of a Real Life Mathematician, Andrew Vazsonyi recalls giving the same incorrect “obvious” answer to the problem on his first encounter; perhaps more shockingly, he details an account of discussing the problem with Paul Erdös, who also got the problem wrong and became increasingly irate about it until he was eventually shown a simulation proving what the right answer should be."
  },
  {
    "objectID": "posts/2022-07-10-monty-hall/index.html#the-correct-answer",
    "href": "posts/2022-07-10-monty-hall/index.html#the-correct-answer",
    "title": "Let’s Make a Deal!",
    "section": "The Correct Answer",
    "text": "The Correct Answer\nThat right answer is that switching is better. Indeed, staying with your original choice will grant you a \\(1/3\\) chance of winning, and switching will grant a \\(2/3\\) chance of winning. The key detail, of course, is Monty’s knowledge of the prize location and his choice of exactly how to reveal what he knows. There are many ways to see why this is true; the Wikipedia entry for the Monty Hall problem gives many different explanations of many different flavors (and even criticisms of those same explanations). These explanations are great, but to those who aren’t accustomed to long mathematical arguments, they might be less than convincing.\nThe first explanation of the solution in the Wikipedia article states:\n\nWhen the player first makes their choice, there is a \\(2/3\\) chance that the car is behind one of the doors not chosen. This probability does not change after the host reveals a goat behind one of the unchosen doors.\n\nThis explanation never quite sat right with me. Sasha Volokh expressed my vague concern quite well:\n\nFirst, it’s clear that any explanation that says something like “the probability of door 1 was 1/3, and nothing can change that…” is automatically fishy: probabilities are expressions of our ignorance about the world, and new information can change the extent of our ignorance.\n\nThis is a case where simulations can do us some good."
  },
  {
    "objectID": "posts/2022-07-10-monty-hall/index.html#simulations",
    "href": "posts/2022-07-10-monty-hall/index.html#simulations",
    "title": "Let’s Make a Deal!",
    "section": "Simulations",
    "text": "Simulations\nWe’ll write Monte Carlo simulations in R to see that by sticking with our original answer, the probability of winning is indeed \\(1/3\\). We will write a function that simulates one full round of the game; then, we’ll replicate() the function many times to determine the probability of winning. Our strategy will be to simulate a round of the full game many times and keep track of how often the game results in a win.\nFor our first attempt, we’ll recreate a very general version of the game:\n\nthe prize can be found behind any of 3 doors\nthe contestant will pick any of 3 doors\nMonty will reveal one door and offer a chance to switch\nthe contestant will choose to switch or stay depending on the parameter stay\n\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\n\nmonty_hall <- function(stay){\n    \n  doors <- c(\"A\", \"B\", \"C\")              # using ABC due to a quirk in sample()\n\n  prize_door <- sample(doors, 1)\n  contestant_choice <- sample(doors, 1)\n    \n  reveal_door <-                                # Monty can't reveal door with the prize,\n    union(prize_door, contestant_choice) %>%    # nor the selected door, so...\n    setdiff(doors, .) %>%                       # we remove those choices \n    sample(1)  \n\n  switch_offer <- setdiff(doors, c(contestant_choice, reveal_door))\n    \n  ifelse(prize_door == ifelse(stay, contestant_choice, switch_offer),\n         \"win\", \"lose\")\n    # the function returns the strings \"win\" and \"lose\"\n    # when stay is TRUE, check if the prize door matches the contestant's choice\n    # when stay is FALSE, check if the prize door matches the door offered in a switch\n}\n\nNext, we’ll generate 10K trials of the game under each of the two options (switching and staying). We’ll reshape the outcomes just a bit and then plot them.\n\nmonty_stay_trials <- replicate(10000, monty_hall(stay = TRUE))\nmonty_switch_trials <- replicate(10000, monty_hall(stay = FALSE))\n\ndata.frame(stay = monty_stay_trials, switch = monty_switch_trials) %>%\n  pivot_longer(everything(), names_to = \"choice\", values_to = \"outcome\") %>% \n  ggplot(aes(x = outcome)) +\n    geom_bar(stat = \"count\") +\n    facet_wrap(~choice) +\n    labs(title = \"Monty Hall Monte Carlo simulation results\",\n         subtitle = \"10,000 trials per contestent choice possibility\") +\n    theme(text = element_text(size = 20))\n\n\n\n\nThe simulations show us exactly what we expected; switching is good, staying is bad. We can also easily confirm that the probability of winning by switching is \\(2/3\\):\n\nmean(monty_switch_trials == \"win\")\n\n[1] 0.6657\n\n\nOur answer is close to \\(2/3\\), and the difference between it and \\(2/3\\) is a small statistical fluctuation, as expected.\nSo, good news: we have confirmed that the correct answer is indeed correct. But can we render any deeper insights from this? Let’s focus on the function in the case when stay == TRUE. In that case, the code looks like this:\nmonty_hall <- function(stay){\n    \n  doors <- c(\"A\", \"B\", \"C\")      \n\n  prize_door <- sample(doors, 1)\n  contestant_choice <- sample(doors, 1)\n    \n  reveal_door <- \n    union(prize_door, contestant_choice) %>%    \n    setdiff(doors, .) %>%                       \n    sample(1)  \n\n  switch_offer <- setdiff(doors, c(contestant_choice, reveal_door))\n    \n  ifelse(prize_door == contestant_choice, \"win\", \"lose\")\n}\n\nHere, switch_offer doesn’t actually get used at all in the line that returns the function. This means that the switch_offer <- ... line, and the reveal_door <- ... lines, are unused appendages. If we remove them, we’re left with this:\nmonty_hall <- function(stay){\n    \n  doors <- c(\"A\", \"B\", \"C\")      \n\n  prize_door <- sample(doors, 1)\n  contestant_choice <- sample(doors, 1)\n    \n  ifelse(prize_door == contestant_choice, \"win\", \"lose\")\n}\nNow, we see that our code has reduced to a simulation that draws two objects independently from a collection of three and checks to see if they’re the same. That probability is clearly \\(1/3\\), and this explanation now aligns perfectly with the Wikipedia explanation that nothing has changed the original probability of \\(1/3\\), whether that explanation is “fishy” or not."
  },
  {
    "objectID": "posts/2022-07-10-monty-hall/index.html#takeaway",
    "href": "posts/2022-07-10-monty-hall/index.html#takeaway",
    "title": "Let’s Make a Deal!",
    "section": "Takeaway",
    "text": "Takeaway\nIt’s great to be able to use Monte Carlo simulations to confirm a correct answer, but in this case the act of writing a simulation can do something more profound: it can make the why behind the answer just a bit more convincing. Or, at least, it did that for me. I’ve seen (and believed, and produced) many analytical arguments for why switching has a \\(2/3\\) probability, but I never fully believed the Wikipedia explanation until writing code to simulate the game."
  },
  {
    "objectID": "posts/2022-07-27-ordered-objects/index.html",
    "href": "posts/2022-07-27-ordered-objects/index.html",
    "title": "Hey, Who Invited You?",
    "section": "",
    "text": "Photo by Surendran MP on Unsplash"
  },
  {
    "objectID": "posts/2022-07-27-ordered-objects/index.html#the-incorrect-answer",
    "href": "posts/2022-07-27-ordered-objects/index.html#the-incorrect-answer",
    "title": "Hey, Who Invited You?",
    "section": "The Incorrect Answer",
    "text": "The Incorrect Answer\nMy immediate answer was: No, that must just be a coincidence."
  },
  {
    "objectID": "posts/2022-07-27-ordered-objects/index.html#the-correct-answer",
    "href": "posts/2022-07-27-ordered-objects/index.html#the-correct-answer",
    "title": "Hey, Who Invited You?",
    "section": "The Correct Answer",
    "text": "The Correct Answer\nI was wrong. The true answer was actually \\(e\\). Well, almost.\n(Quick disclaimer: this result is perfectly well-known to humanity; it just wasn’t well-known to me at the time.)\nWhen the student asked me this question, I replicated my answer a few more times to see if I still thought the resemblence to the magic number \\(2.718282...\\) was accidental.\n\nmean(replicate(10000, letters_until_unordered()))\n\n[1] 2.7228\n\n\nHmmm…\n\nmean(replicate(10000, letters_until_unordered()))\n\n[1] 2.726\n\n\nVery suspicious. Let’s try using more replications for finer accuracy:\n\nmean(replicate(1e5, letters_until_unordered()))\n\n[1] 2.71936\n\n\nHMMMM…..\n\nmean(replicate(1e6, letters_until_unordered())) \n\n[1] 2.717368\n\n# runtime starts to get a little long: ~50 seconds on my machine\n\nThat was hard to ignore, and it practically reeked of Euler’s number. This caught me completely off guard; I had written the problem without any idea that \\(e\\) belonged here at all, and yet… here it was. On the one hand, I shouldn’t have been surprised at all. This is just a Thing That Happens with certain famous mathematical constants like \\(e\\) and \\(\\pi\\); they frequently show up where they frankly have no business being.\nI did find myself surprised, though – mostly, by the fact that I had encountered an experiment-driven result, which I am not at all accustomed to. I don’t think I would ever have considered this result were it not for this esoteric homework problem I conjured up (and the help of the keen-eyed student). Monte Carlo simulations gave me something that I imagine must feel a little bit like when a physicist can’t explain a bump on a curve, or when a biologist sees a bacterial growth rate that has no known explanation. The next step for that physicist, or that biologist, and for me, was to ask why.\nIn this way, I was behaving in the most analogous way possible to an experimental scientist. Such a scientist might discover a fascinating new result in a lab; new results yearn for new theories, and it is those theories that are powerful. Theories are what convey existing and lasting knowledge to humanity. The experiments themselves matter only insofar as they suggest or reveal deeper truths; but the experiments themselves are but partial reflections of those truths. This homework problem doesn’t matter; what makes it tick matters.\nThis also helped crystallize to me an important lesson about the pedagogy of mathematical education. One of my most important missions in my own classrooms has been to transfer as much agency to students as possible. I tend to gravitate strongly toward active learning strategies. My teaching philosophy is fairly simple: anything students do is good, and anything I do is inherently less good. Here, too, I’ve long been jealous of lab sciences; they have a built-in pedagogy to invite students to meaningfully engage, right from the very beginning of study. Teaching a course on Monte Carlo simulations has been the first thing I’ve done that has felt just a little bit like a lab.\nAnd yet, the simulations have also underscored for me the importance of understanding “traditional” mathematics; we can discover wildly interesting results through Monte Carlo simulations, but only mathematical reasoning can deliver the all-important why. Simulations are a wonderful way to augment a traditional probability and statistics curriculum, but I don’t think they should replace it."
  },
  {
    "objectID": "posts/2022-07-27-ordered-objects/index.html#takeaway",
    "href": "posts/2022-07-27-ordered-objects/index.html#takeaway",
    "title": "Hey, Who Invited You?",
    "section": "Takeaway",
    "text": "Takeaway\nMonte Carlo simulations have given me a new way to invite students who can write just a bit of code to experiment and to play in a mathematical space. Inviting students into this style of mathematical “laboratory” has been incredibly rewarding, and it has allowed me to engage students much more fully than I’m typically able to do in introductory probability / statistics classes. It has allowed me to transfer some of the ownership of the subject material to students, which seems to me an unqualified good thing.\nHowever, Monte Carlo simulations are inherently limited in scope. They can give us incredibly interesting results, and they can do so in a much more accessible way than can classical mathematics and statistics. But by themselves, they can never give us that elusive why."
  },
  {
    "objectID": "posts/2022-07-27-ordered-objects/index.html#wait-what-about-the-why-part",
    "href": "posts/2022-07-27-ordered-objects/index.html#wait-what-about-the-why-part",
    "title": "Hey, Who Invited You?",
    "section": "Wait, what about the “Why” part?",
    "text": "Wait, what about the “Why” part?\nIt would be pretty unsatisfying if after all that discussion, we didn’t get around to the proof of the aforementioned result. Once again, to be clear, this result is perfectly well-known; I just hadn’t personally encountered it before. Once the student brought this seeming coincidence to my attention, I immediately set out to try to prove it.\nTo remind ourselves, here’s the result:\n\nTheorem\nSuppose you repeatedly draw upper-case letters from a jar without replacement until the first time you get one that is out of order. The expected number of draws executed in this fashion will be very slightly less than \\(e\\).\n\n\nProof\nFor \\(k \\geq 1\\), let \\(A_k\\) denote the event that the first \\(k\\) letters drawn are all in order. (That is: \\(A_1\\) is trivial, \\(A_2\\) holds only if the first two letters are drawn in order, and so forth.) If we let \\(N\\) denote random variable of the number of letters drawn until finding one out of sequence, then we note that \\[ N = 1 + \\mathbb 1_{A_1} + \\mathbb 1_{A_2} + \\dots + \\mathbb 1_{A_{26}}\\] where \\(\\mathbb 1_{B}\\) denotes the indicator function of event \\(B\\). This is both the most important and least obvious step in the proof; the logic of this step is that \\(N\\) and each \\(\\mathbb 1_{A_k}\\) are random variables, meaning they’re functions of some unseen input variable \\(\\omega\\). Here, choosing an \\(\\omega\\) determines a full ordering of the letters, and once this has been done, a certain number of events \\(\\{A_1, \\dots, A_n\\}\\) will be fulfilled, making their corresponding indicator variables evaluate to \\(1\\) on that \\(\\omega\\). Summing these indicators will therefore count the events, as desired.\nThe leading \\(1\\) in the above expression is meant to count the one letter we’ll draw that’s out of order and therefore not counted by the indicator variables; technically, this isn’t very well-defined for the case when we draw all 26 letters in order, but that’s a very low-probability event that we were explicitly invited in the problem statement to ignore, so we’ll just accept the fact that \\(N\\) evaluates to \\(27\\) in that case. (I originally added that detail in the problem statement to alleviate a coding nuisance, and it turned out to alleviate a corresponding mathematical nuisance here.)\nThe decomposition above is useful, because it therefore follows that \\[ \\mathbb E[N] = 1 + \\mathbb E \\left[ \\mathbb 1_{A_1} \\right] + \\mathbb E \\left[ \\mathbb 1_{A_2} \\right] + \\dots + \\mathbb E \\left[ \\mathbb 1_{A_{26}} \\right] = 1 + \\sum_{k=1}^{26} \\mathbb E \\left[ \\mathbb 1_{A_k} \\right].\\] I should stop and explicitly acknowledge that this really, really feels like we’re cheating somehow. The \\(\\{A_k\\}\\) events are definitely not independent; in fact, they’re completely dependent, as \\(A_{k+1} \\subset A_k\\). (If the first twelve letters were perfectly ordered, then the first eleven were also.) However, independence is not required for linearity of expectation.\nFrom here, we recall that \\(\\mathbb E \\left[ \\mathbb 1_B \\right] = \\mathbb P(B)\\) for any event \\(B\\), which means that we need only to compute \\(\\mathbb P(A_k)\\). When drawing \\(k\\) objects, there are \\(k!\\) rearrangements of those objects, of which only \\(1\\) is properly ordered, from which it follows that \\(\\mathbb P(A_k) = \\frac 1 {k!}\\). Hence, \\[\\mathbb E[N] = 1 + \\sum_{k=1}^{26} \\mathbb P \\left( A_k \\right) = 1 + \\sum_{k=1}^{26} \\frac{1}{k!} = \\sum_{k=0}^{26} \\frac{1}{k!}\\] and we notice that this is simply the first few terms of the infinite series \\[\\sum_{k=0}^{\\infty} \\frac{1}{k!} = e.\\]\nSo, the true expected value in our original question isn’t quite \\(e\\) – it’s a number just below it. Specifically, it’s \\(e - \\sum_{k=27}^{\\infty} \\frac{1}{k!}\\). To see how close this is to \\(e\\), let’s use R to sum the first few terms of the remainder series:\n\nsum(1 / factorial(27:1000))\n\n[1] 9.523378e-29\n\n\nPretty close to \\(e\\), indeed. And while the true answer isn’t actually quite \\(e\\), we were never going to be able to distinguish the true answer from \\(e\\) with only a Monte Carlo simulation."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Please excuse my dust! I’m trying to work with a brand new work flow. How did you even find this, anyway?\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  }
]